# ğŸ”Œ Plugâ€‘andâ€‘Play Navigation Framework using Visionâ€‘Language Model

> A modular, extensible framework for languageâ€‘guided embodied navigation that leverages a Visionâ€‘Language Model (VLM) (tested with Qwen2.5â€‘VL) to translate raw simulator observations into highâ€‘level actions.

---

## ğŸ“– Table of Contents

- [ğŸš€ Overview](#-overview)  
- [ğŸ–¼ Architecture](#-architecture)  
- [âœ¨ Features](#-features)   
- [ğŸš¦ Quick Start](#-quick-start)  
- [ğŸ›  Configuration](#-configuration)  
- [ğŸ¤ Contributing](#-contributing)  
- [ğŸ“„ License](#-license)  
- [ğŸ“š Citation](#-citation)

---

## ğŸš€ Overview

This project implements a **plugâ€‘andâ€‘play navigation loop** comprised of four interchangeable modules:

1. **Visual Interpreter** â€” Extracts scene representations (objects, depth) from raw simulator observations.  
2. **VLM Agent (Qwen2.5â€‘VL)** â€” Receives visual inputs + historic context to generate naturalâ€‘languageâ€‘grounded navigation actions.  
3. **Action Interpreter** â€” Converts highâ€‘level action tokens into simulator API calls.  
4. **Simulator Wrapper** â€” Provides a unified interface to 3D environment

A **History Manager** persistently stores timestep metadata.

---

## ğŸ–¼ Architecture

![Framework Architecture](docs/architecture.png)

1. Simulator â†’ Visual Interpreter  
2. Visual Interpreter â†’ VLM Agent  
3. VLM Agent â†’ Action Interpreter  
4. Action Interpreter â†’ Simulator  

History Manager maintains bidirectional context with VLM Agent.

---

## âœ¨ Features

- ğŸ”„ **Modular design** â€” swap in/out any Vision model, simulator, or planner  
- ğŸ“Š **Persistent memory** â€” builds steps history for memory and refelection.
- ğŸ’¬ **Naturalâ€‘language actions** â€” driven by stateâ€‘ofâ€‘the-art VLM (Qwen2.5â€‘VL)  
- âš™ï¸ **Simulatorâ€‘agnostic** â€”  Habitat-lab

---

## ğŸš¦ Quick Start
To run the evaluation: 
```bash
python run.py
```

---

## ğŸ›  Configuration
Make one `.local.yaml` first.
All hyperparameters live in `.local.yaml`. Key sections:

```yaml
mp3d_habitat_scene_dataset_path: "<your path>/mp3d/"
r2r_dataset_path: "<your path>/R2R_VLNCE_v1-3/val_unseen/val_unseen.json.gz"
eval_config: 'r2r_eval.yaml'
success_distance: 3
```
---

## ğŸ¤ Contributing

1. Fork â†’ Clone â†’ Create feature branch  
2. Add tests for new modules  
3. Submit PR â†’ Review â†’ Merge  

---

## ğŸ“„ License

This project is MIT Licensed. See `LICENSE` for details.

---

## ğŸ“š Citation

If you find our work helpful, feel free to give us a cite:
```
@misc{oobvlm,
    title = {Plugâ€‘andâ€‘Play Navigation Framework using Visionâ€‘Language Model},
    url = {https://github.com/YichengDuan/oobvlm},
    author = {Yicheng Duan, Kaiyu Tang},
    month = {April},
    year = {2025}
}
```
